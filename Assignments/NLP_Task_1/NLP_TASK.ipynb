{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to install dependencies [Remember to make the statement true]\n",
    "if 0 == 1:\n",
    "    !pip3 install pandas\n",
    "    !pip3 install tqdm\n",
    "    !pip3 install scikit-learn\n",
    "    !pip3 install gensim\n",
    "    !pip3 install spacy\n",
    "    !python3 -m spacy download en\n",
    "    !pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import W2V lib\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "DATA_LIMIT = 1000\n",
    "\n",
    "df = pd.read_csv('./imdb_master.csv', encoding='latin1')\n",
    "df_neg = df[df['label'] == 'neg']\n",
    "df_pos = df[df['label'] == 'pos']\n",
    "df = pd.concat((df_pos[:DATA_LIMIT], df_neg[:DATA_LIMIT]))\n",
    "df_test = pd.concat((df_pos[DATA_LIMIT:1500], df_neg[DATA_LIMIT:1500]))\n",
    "\n",
    "def process_text(input_string, return_string=False, stem=False):\n",
    "    text = nlp(u'' + input_string)\n",
    "    if stem == True:\n",
    "        text = [tok.lemma_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    else:\n",
    "        text = [tok.lower_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    if return_string == True:\n",
    "        return \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:14<00:00, 14.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make this statement true to run from scratch [It takes time to process the text]\n",
    "if 1 != 0:\n",
    "    wordlist = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        wordlist.append(process_text(df['review'].iloc[i]))\n",
    "        \n",
    "    with open('vocabulary.txt', 'wb') as vocabulary:\n",
    "        pickle.dump(wordlist, vocabulary)\n",
    "    vocabulary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "wordlist = []\n",
    "with open('vocabulary.txt', 'rb') as vocabulary:\n",
    "    wordlist = pickle.load(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens - 5464\n",
      "Dictionary(5464 unique tokens: ['clear', 'moving', 'standards', 'understood', 'city']...)\n",
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "['i', 'went', 'saw', 'movie', 'night', 'friends', 'i', 'admit', 'i', 'i', 'knew', 'able', 'comedy', 'i', 'wrong', 'played', 'character', 'jake', 'kevin', 'played', 'ben', 'the', 'sign', 'good', 'movie', 'toy', 'emotions', 'this', 'exactly', 'the', 'entire', 'theater', 'sold', 'overcome', 'laughter', 'half', 'movie', 'moved', 'tears', 'second', 'half', 'while', 'theater', 'i', 'saw', 'women', 'tears', 'grown', 'men', 'trying', 'desperately', 'let', 'crying', 'this', 'movie', 'great', 'i', 'suggest', 'judge']\n"
     ]
    }
   ],
   "source": [
    "# Keeping track of frequency of a single token\n",
    "frequency = defaultdict(int)\n",
    "for text in wordlist:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "# Apply Threshold to limit the vocabulary size, discarding the tokens which appeard number of times below the threshold limit \n",
    "FREQ_THRESHOLD = 5\n",
    "\n",
    "thresholded_wordlist =  [[token for token in text if frequency[token] > FREQ_THRESHOLD]\n",
    "          for text in wordlist]\n",
    "\n",
    "# Create Dictionary based on the word list\n",
    "dictionary = Dictionary(thresholded_wordlist)\n",
    "\n",
    "# Number of tokens\n",
    "print(\"Number of Tokens - {}\".format(len(dictionary)))\n",
    "print(dictionary)\n",
    "print(type(dictionary))\n",
    "print(thresholded_wordlist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.imgur.com/f1uzTDZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* From the screenshot you can see the implementation of word-cooccurance matrix, based on the tokens from the dictionary, build a word-cooccurance matrix yourself which is $X$. Documentation of gensim [https://radimrehurek.com/gensim/corpora/dictionary.html]\n",
    "* Apply SVD on $X$\n",
    "* Reduce Dimension \n",
    "\n",
    "![dimen_reduc](https://i.imgur.com/lezB870.png)\n",
    "\n",
    "* Here Richard is taking only top two dimensions of the vector $U$, recommended size is *50* for now.\n",
    "\n",
    "![dimen_reduc_u](https://i.imgur.com/TA2Bmsq.png)\n",
    "\n",
    "* Now we can get a fixed size vector for each word. \n",
    "\n",
    "* Try to plot something similar based on the given dataset. In class we will try to implement a logistic regression classifier that can classify positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(dictionary), len(dictionary)))\n",
    "# print(X.shape)\n",
    "\n",
    "for word in thresholded_wordlist:\n",
    "    \n",
    "    idx = dictionary.doc2idx(word)\n",
    "    \n",
    "    for i in idx:\n",
    "        for j in idx:\n",
    "            X[i, j] += 1\n",
    "\n",
    "# print(X)\n",
    "np.fill_diagonal(X, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(X[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = np.linalg\n",
    "U, s, Vh = la.svd(X, full_matrices=False)\n",
    "\n",
    "U_reduced = U[:, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5464, 50)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFJCAYAAAAVJ240AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGpRJREFUeJzt3X+YXmV95/H3JxPASoCoCVslQKzyw8Aq6IisrhpXVGQtrJfaBWURV2WtjbaK7tJalVovq2uru1RcS1fL6vobrWYpSlcLalEsw4rIT00jSsBKBOSHFEKS7/5xzpBxnNwZQp7nCTPv13XNNc9zzn3OfJ87M3k+z33uc06qCkmSpK1ZMOoCJEnSzs2wIEmSmgwLkiSpybAgSZKaDAuSJKnJsCBJkpoMCxqoJB9JclOSK7ayPknOSLImyeVJnjjsGiVJbYYFDdrZwNGN9c8HDui/TgH+xxBqkiTdD4YFDVRVfR24pdHkOOCj1bkYWJzkkcOpTpI0GwtHXYDmvX2A66c8X9cv+8nURklOoRt5YPfdd3/SwQcfPLQCJWkuuPTSS39WVUu3Z1vDgh4Uquos4CyA8fHxmpiYGHFFkvTgkuRH27uthyE0ajcA+055vqxfJknaSRgWNGqrgZP6syKOBG6rqp9sayNJ0vB4GEIDleSTwEpgSZJ1wNuBXQCq6kPAecAxwBrgLuAVo6lUkrQ1hgUNVFWdsI31BfzOkMqRJG0HD0NIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWraZlhI8s1hFCJJknZO2wwLVfXUYRQiSZJ2TrMZWbhzGIVIkqSdk3MWJElSk2FBkiQ1GRYkSVKTYUGSJDUZFiRJUtNsTp1cNIxCJEnSzsmRBQ1UkqOTXJtkTZLTZli/X5ILknwnyeVJjhlFnZKkrTMsaGCSjAFnAs8HVgAnJFkxrdkfAp+pqsOB44EPDrdKSdK2GBY0SEcAa6pqbVVtAD4FHDetTQF79o/3Am4cYn2SpFkwLGiQ9gGun/J8Xb9sqtOBE5OsA84DXjfTjpKckmQiycT69esHUaskaSsMCxq1E4Czq2oZcAzwsSS/8ntZVWdV1XhVjS9dunToRUrSfGZY0CDdAOw75fmyftlUrwQ+A1BV3wIeAiwZSnWSpFkxLGiQLgEOSPLoJLvSTWBcPa3Nj4FnAyR5HF1Y8DiDJO1EDAsamKraCKwCzgeupjvr4cok70hybN/sVODVSb4LfBI4uapqNBVLkmaycNQFaG6rqvPoJi5OXfa2KY+vAp427LokSbPnyIIkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCBirJ0UmuTbImyWlbafNbSa5KcmWSTwy7RklS28JRF6C5K8kYcCbwHGAdcEmS1VV11ZQ2BwC/Dzytqm5NsvdoqpUkbY0jCxqkI4A1VbW2qjYAnwKOm9bm1cCZVXUrQFXdNOQaJUnbYFjQIO0DXD/l+bp+2VQHAgcmuSjJxUmOnmlHSU5JMpFkYv369QMqV5I0E8OCRm0hcACwEjgB+Mski6c3qqqzqmq8qsaXLl065BIlaX4zLGiQbgD2nfJ8Wb9sqnXA6qq6t6p+CHyfLjxIknYShgUN0iXAAUkenWRX4Hhg9bQ2X6AbVSDJErrDEmuHWaQkqc2woIGpqo3AKuB84GrgM1V1ZZJ3JDm2b3Y+cHOSq4ALgDdX1c2jqViSNJNU1ahrkO6X8fHxmpiYGHUZkvSgkuTSqhrfnm0dWZAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgUNVJKjk1ybZE2S0xrtXpSkkowPsz5J0rYZFjQwScaAM4HnAyuAE5KsmKHdHsDvAt8eboWSpNkwLGiQjgDWVNXaqtoAfAo4boZ2fwy8B7h7mMVJkmbHsKBB2ge4fsrzdf2y+yR5IrBvVf1Na0dJTkkykWRi/fr1O75SSdJWGRY0MkkWAO8DTt1W26o6q6rGq2p86dKlgy9OknQfw4IG6QZg3ynPl/XLJu0BHApcmOQ64EhgtZMcJWnnYljQIF0CHJDk0Ul2BY4HVk+urKrbqmpJVS2vquXAxcCxVTUxmnIlSTMxLGhgqmojsAo4H7ga+ExVXZnkHUmOHW11kqTZWjjqAjS3VdV5wHnTlr1tK21XDqMmSdL948iCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElqMixIkqQmw4IkSWoyLEiSpCbDggYqydFJrk2yJslpM6x/Y5Krklye5KtJ9h9FnZKkrTMsaGCSjAFnAs8HVgAnJFkxrdl3gPGqejxwDvBfh1ulJGlbDAsapCOANVW1tqo2AJ8CjpvaoKouqKq7+qcXA8uGXKMkaRsMCxqkfYDrpzxf1y/bmlcCX5ppRZJTkkwkmVi/fv0OLFGStC2GBe0UkpwIjAPvnWl9VZ1VVeNVNb506dLhFidJ89zCURegOe0GYN8pz5f1y35JkqOAtwDPrKp7hlSbJGmWHFnQIF0CHJDk0Ul2BY4HVk9tkORw4C+AY6vqphHUKEnaBsOCBqaqNgKrgPOBq4HPVNWVSd6R5Ni+2XuBRcBnk1yWZPVWdidJGhEPQ2igquo84Lxpy9425fFRQy9KknS/OLIgSZKaDAuSJKnJsCBJkpoMC5IkqcmwIEmSmgwLkiSpybAgSZKaDAuSJKnJsCBJkpoMC5IkqcmwIEmSmgwLkiSpybAgSZKaDAuSJKnJsCBJkpoMC5IkqcmwIEmSmgwLkiSpybAgSZKaDAuSJKnJsCBJkpoMC5IkqcmwIEmSmgwLkiSpybAgSZKaDAuSJKnJsCBJkpoMC5IkqcmwIEmSmgwLelBIcnSSI7Zn23e96107uhxJmlcMC9qpJVme5FrgfcC3k9Sll15Kkll/veUtb7lf7Xfk19jYGEk45JBD2Guvvdhjjz0YGxvjc5/7HM9+9rM56qijWL58OT/72c8YGxtjl1124Ytf/CKveMUr+MpXvnLfuukWLVoEwMknn8w555zDypUrmZiYGO4/jqR5I1U16hqkX5FkOfCPwPnA80dazE5kbGyMBQsWcO+997Jw4UI2btzIwx72MDZu3MiyZctYsWIFN954I9/85je58MILec5znsNJJ53EW9/6Vl7wghfwzne+kwMPPJBjjjmGiYkJlixZwsaNG1m4cOGoX5qkAUtyaVWNb9e2hgWNSpJLgcOBa4APA/8MHAG8HPgpsBRHv2Zl4cKFbN68mSc84QnceeedfPjDH2bTpk0861nP4qCDDmK33Xbj2muv5fDDD+fUU09l1apVLF++nL333ptrrrmG73//+6N+CZIGzLCgB4V+tODcqjp0yvO1wC19k0eMoq75YjJQ7Lrrrtx9990k4VWvehXPeMYzOOOMM9iwYQNPecpT+OAHP8jY2Nioy5W0gz2QsOCnNg3biiSbktwL/BAIXUgwKOxgSX7p8caNG1mwYAG77bYbS5cu5cgjj+Tcc8/l7LPP5qKLLuKyyy5jbGyMj3/84yOsWtLOyLCgWUmyOMlr+8crk5w7Zd3vJXlo//h/JlmR5PVJrk5yR5L1SdYA/5suHCwA/Og6YLvtthsAe+65Jw9/+MPZdddd2WuvvRgfH2fBggUsWrSIxYsXc9lll/HkJz+Zww47jK9+9ausXbt2xJVL2tk4q0mztRh4LfDBGda9CfhPwOOq6lUAST4PPBe4AHgO8EzgrCnbZPpOtGNt3LgRgM2bN7N582YANm3a9EttkvC85z3P0QRJTYYFzda7gcckuRzYD1iY5HbgoXRv/EuSXNA//jXgQOBH/bb/CBQGhKGaDAtJuPXWWwHuO5Ni0pIlS/ja177GTTfdxN57780tt9zCHXfcwf777z+SmiXtnJzgqFmZnJwIvB14BfB04HnAR4DHADcBXwdeSHeY4Q5gyZRdbMJDD6NWdJNJF9P9G10DPAq4q1822ebHwC9GUeADtAT41YtSzE/2xRb2xRYHVdUe27OhIwu6v74HjNO96exL96azAFhG98azFngc8LBp2xkUHpi76EZsAmym6/O76fr1J3SnmX6CLgDsRfeG/2fA4qraPIqChy3JxPbO9J5r7Ist7Istkmz3ldsMC9qmJIuBE/und9IdVngocCpwEN2b1gK6wxP79e0WAPcAuw212LnroVMeT05M3gDsAuxOFw4eSXediluApwGnzpegIGmwDAvaqiRvpQsJt9PNQdgMHAI8HNgHWEMXFDYAD6F7E5s82wHmXlC4my2vbxe6C0d9HngB3ev/GvAHwGfohj4fBayn66+bgR8Az6mqe6buNMmfAkf1+/hb4HerPz7YB7V/AL5bVS+ZXpCfmiQNg2FBM0ryZOBFwBPoTnl8Et2b5fl9kzvo5irsAkzOmNurb7P7UIudnV/wq3VtohvC/3W6Yf7d2XK4ZBPd8fvT6Ib3fwBcRHePii8Cf19VT+/bvnbafg9PciFdQNgVOK2qzt5aYVX1psa6n9MFta05q7FuvrEvtrAvtrAvttjuvnCCo2aU5PeAh1XV2/vJjRPAnwOnALdW1aFJ3gX8PvBfgPfQjTz8gm5EYYwtIw2DMDlhcjPdJ+8j6d7cN/Q/v+gCze19HT+je9N9CN2n/b3oAsAquk/zC4Cf9/UvpQsRRReob+738yS6OQGXARuqatWAXpsk7VS8KJMeqE10Z0ZAN8LwzP7x5JD9ppk2mqaA27ay7pYpjzf3+9tEFwoK+G/Af+6XhW6k4xbgiqraiy1v8GN0IyT/RDcx86B+n/vRHU74BPCBqtof+A/ARrrRhsfRTei8Gnh7VR1RVacYFCTNJ4YFbc1FwG8meQjd5Lo96D5138aWyXYrgCuA19FNZizgc/33b9G9CU8O699F94a+ke5Nf3IUALo39xP6ZdCFjsnj+puB6/vvN9BdAKrYMoFy96r6RlUtrKpU1VhVPaKqHt9vfxvwvP5+FB8BflpV91TVdVV1aFV9tKr2raqTqup0gKr6XFUdBPxV/zqupBuJ+Ivt705JevAyLMwjSb7Zf1+e5KWttlV1CbAauJzujpAb6d543wT8+pSLM13Sb7KO7vfpEXSf7g+m+6R/Rb9+N7aMBvwT3TD/06oqdOf4v7xvfw/d2RZrgOv6bRb3z/cFvty3+Trdm//DkqxJ8u3+cMl0+wGXJPkucAbw6m121JY+eH9VHVZVK6rqZVV112y33dGSHJ3k2v61njbD+jcmuSrJ5Um+mmTOXlVpW30xpd2LklSSOTsBdDZ9keS3+t+NK5N8Ytg1Dsss/kb2S3JBku/0fyfHjKLOQUvykSQ3JbliK+uT5Iy+ny5P8sRZ7biq/JpnX8BKurs/bqvdov77Q+mO268BPks3xA9wMvABYDldKLiO7pbTV/Tr/pruWP8z6d7k76YbYbgZ+H90w/u70AWI36QLIxcCf0g3InEn3eTBK/r9rOh/7p3999cCH+ofHw98etR9O6B/rzG6APUbdBMmvzvZF1PaPAt4aP/4t+dzX/Tt9qALlBcD46Oue4S/FwcA36GbfwSw96jrHmFfnAX8dv94BXDdqOseUF88A3ji5P/TM6w/BvgS3YezI4Fvz2a/jizMI0nu7B++G3h6ksuSvKGxyVlJLqN7Y//TqnpsVb2k+ltMV9XZVbWqtgzpLwdunVwH/He6gPHndGcc3A78CfBsuj/qT9BNFtxId3XIw+hGEd7Qb7eZ7p4TuwD/BzhuWn3HAf+rf3wO8OxMvdXi3HEEsKaq1lbVBuBTTOuLqrqgtox8XEx3kay5aJt90ftjukm3dw+zuCGbTV+8Gjizqib/Lm8aco3DMpu+KGDP/vFewI1DrG9oqurr/PJcr+mOAz5anYuBxUkeua39Ghbmp9OAb1Q3xP7+rTWqqpf2bQ6uqj/Zzp91Y1U9vqoOo7v+wPVVdRldSHhpVR0C3NP/4v4QeCddMHgz3eGKS+hGGL5Bd20HqmpRv+996OYzUFWTh0nm4q2u73udvXX9sq15Jd0nh7lom33RD6vuW1V/M8zCRmA2vxcHAgcmuSjJxUmOHlp1wzWbvjgdODHJOuA8urlW89H9/f8EMCxox7uDbgh4R/ky3UjIqXQjDGpIciLd4Z33jrqWUUiygO5aGKeOupadxEK6QxEr6SYR/2V/oa/56ATg7KpaRjcU/7H+90WzYEf1kixO8tr+8cok5466pgejqroZuKifXPNA3rBuoL+IUlV9lu4Y5FFJfm1am30BkiykG1q8+QH8zJ3Vfa+zt6xf9kuSHAW8BTi2pl0lcg7ZVl/sARwKXJjkOrpjsqvn6CTH2fxerANWV9W9/cjd9+nCw1wzm754Jd3oJlX1Lbprrixh/pnV/yfTGRa2WMyvXolvrtrRn/5/SX/44tCqenJVvWDK8lX9XAaqamVVTfSPF01pc05VnUx3+OEe4NIku9L9B3dsVf3zlB+1mu4sCoAXA39X/QyeOeYS4IAkj+774ni6136fJIfTndp57Bw+Lg3b6Iuquq2qllTV8n4OzcV0fbLdN9DZiW3z9wL4At2oAkmW0B2WWDvMIodkNn3xY7r5UiR5HFsu0DbfrAZO6s+KOBK4rap+sq2NvNzzFu8GHtNP6LsX+EWSc+g+pVwKnFhVleRJdMOci+iuCnjybDp6J3M5sKk/nfDs1ryFUamqjUlW0V1eegz4SFVdmeQdwERVraY7pfNjSdbQTeg5fnQVD84s++K9dL+Tn+3neP64qo4dWdEDMsu+mBdm2RfnA89NchXddU7e3I/+zSmz7ItT6Q7DvIFusuPJc/HDRZJP0gXEJf38jLfTH8Ktqg/Rzdc4hm4S+V3AK2a13znYV9ulP0f/3OouY7yS7vr/h9DNmL2IbsLdt+luFnRcVa1P8u/pLvjzH0dStCRJQ+DIwtb9Q1WtA+hHG5bT3TvgUOD/9p/exuguLiRJ0pzlnIWtmzpBbBNdsApwZX864WFV9S+r6rnDLGryWglJHtUfJiHJyUk+MMw6JEnzh2Fhi9lM+rsWWJrkXwEk2SXJIQOvbAZVdWNVvXgUP1uSNL8YFnqzOeWvvzLYi4H39JMDLwOeOrwqt0h3f4dfufZ3kn+b5FtJliRZmuRzSS7pv542ilolSQ9uzlmYoqpmvLlSTbkdcX/1wWcMraj7IckLgTcCx1TVrf1NY95fVX+fZD+6mcKPG2mRkqQHHcPC3PFv6K7c99yqur1fdhSwYsrtEvZMsqiq7pxpB5IkzcSwMHdM3nHtQGDyAjQLgCOrai7fTEeSNGDOWZg7fgS8CPjolEmXf8uUm6UkOWwUhUmSHtwMC3NIVV0DvIzuKn6PAV4PjCe5vL+C22tGWqAk6UHJKzhKkqQmRxYkSVKTYUGSJDUZFiRJUpNhQZIkNRkWJElSk2FBkiQ1GRYkSVKTYUGSJDUZFiRJUpNhQZIkNRkWJElSk2FBkiQ1GRYkSVKTYUGSJDUZFiRJUpNhQZIkNRkWJElSk2FBkiQ1GRYkSVKTYUGSJDUZFiRJUpNhYSuSvD7J1UluTXJav+z0JG8adW2SJA3TwlEXsBN7LXBUVa0bdSGSJI2SIwszSPIh4DeALyV5Q5IPzNDmwiTvTzLRj0A8Ocnnk/wgyTuHX7UkSYNhWJhBVb0GuBF4FnBro+mGqhoHPgR8Efgd4FDg5CSPGHihkiQNgWHhgVndf/8ecGVV/aSq7gHWAvuOrixJknYcw8IDc0//ffOUx5PPnQ8iSZoTDAuSJKnJsCBJkppSVaOuQZIk7cQcWZAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFiQJElNhgVJktRkWJAkSU2GBUmS1GRYkCRJTYYFSZLUZFi4n5K8JslJo65DkqRhSVWNugZJkrQTm9MjC0mWJ7kmydlJvp/k40mOSnJRkh8kOSLJw5N8IcnlSS5O8vgkC5Jcl2TxlH39IMm/SHJ6kjf1yx6T5MtJLk3yjSQHj+7VSpI0GHM6LPQeC/wZcHD/9VLgXwNvAv4A+CPgO1X1+P75R6tqM/BF4IUASZ4C/Kiqfjpt32cBr6uqJ/X7++DgX44kScO1cNQFDMEPq+p7AEmuBL5aVZXke8ByYH/gRQBV9XdJHpFkT+DTwNuAvwKO75/fJ8ki4KnAZ5NMLt5t8C9HkqThmg9h4Z4pjzdPeb6Z7vXfu5XtvgU8NslS4N8B75y2fgHw86o6bAfWKknSTmc+HIbYlm8ALwNIshL4WVXdXt3Mz78G3gdcXVU3T92oqm4HfpjkJf22SfKEoVYuSdIQGBbgdOBJSS4H3g28fMq6TwMnMu0QxBQvA16Z5LvAlcBxA6xTkqSR8NRJSZLU5MiCJElqMixIkqQmw4IkSWoyLEiSpCbDgiRJajIsSJKkJsOCJElq+v/ek0nDrDFstQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effd01e7908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(dictionary)):\n",
    "        plt.text(U[i, 0], U[i, 1], dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros([2000, 50])\n",
    "for num, review in enumerate(thresholded_wordlist):\n",
    "    vec = 0\n",
    "    idx = dictionary.doc2idx(review)\n",
    "    Ux = U_reduced[idx]\n",
    "    X_train[num, :] += np.sum(Ux, axis=0)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(df['label'] == \"neg\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticreg = LogisticRegression()\n",
    "logreg = logisticreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making test data\n",
    "\n",
    "y_test = np.where(df_test['label'] == 'neg', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:08<00:00, 14.53it/s]\n"
     ]
    }
   ],
   "source": [
    "if 1 != 0:\n",
    "    wordlist_test = []\n",
    "    for i in tqdm(range(df_test.shape[0])):\n",
    "        wordlist_test.append(process_text(df_test['review'].iloc[i]))\n",
    "        \n",
    "    with open('vocabulary_test.txt', 'wb') as vocabulary:\n",
    "        pickle.dump(wordlist_test, vocabulary)\n",
    "    vocabulary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "wordlist_test = []\n",
    "with open('vocabulary_test.txt', 'rb') as vocabulary:\n",
    "    wordlist_test = pickle.load(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.36250142  1.57966846  0.22183352 ... -0.41246801 -0.14549921\n",
      "   0.05411189]\n",
      " [-2.66737559  0.01817039 -0.14336702 ...  0.21287842  0.54081521\n",
      "  -0.87790985]\n",
      " [-1.05857529 -0.3052493   0.14110925 ...  0.17072351 -0.22695934\n",
      "  -0.47253189]\n",
      " ...\n",
      " [-0.87207706  0.70204862 -0.04736584 ...  0.10555553  0.01199151\n",
      "   0.05280231]\n",
      " [-0.20337464 -0.06491143  0.03740263 ...  0.1380559  -0.11969993\n",
      "  -0.20586635]\n",
      " [-1.10801848  0.61766196 -0.04998649 ...  0.18182879 -0.25932028\n",
      "  -0.1723548 ]]\n"
     ]
    }
   ],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in wordlist_test:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "# Apply Threshold to limit the vocabulary size, discarding the tokens which appeard number of times below the threshold limit \n",
    "FREQ_THRESHOLD = 5\n",
    "\n",
    "thresholded_wordlist_test =  [[token for token in text if frequency[token] > FREQ_THRESHOLD]\n",
    "          for text in wordlist_test]\n",
    "\n",
    "# Create Dictionary based on the word list\n",
    "dictionary = Dictionary(thresholded_wordlist_test)\n",
    "\n",
    "\n",
    "X_test = np.zeros([1000, 50])\n",
    "for num, review in enumerate(thresholded_wordlist_test):\n",
    "    idx = dictionary.doc2idx(review)\n",
    "    Ux_test = U_reduced[idx]\n",
    "    X_test[num, :] += np.sum(Ux_test, axis=0)\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_test = logisticreg.fit(X_test, y_test)\n",
    "logreg_test.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import W2V lib\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "DATA_LIMIT = 1000\n",
    "\n",
    "df = pd.read_csv('./imdb_master.csv', encoding='latin1')\n",
    "df_neg = df[df['label'] == 'neg']\n",
    "df_pos = df[df['label'] == 'pos']\n",
    "df = pd.concat((df_pos[:DATA_LIMIT], df_neg[:DATA_LIMIT]))\n",
    "df_test = pd.concat((df_pos[DATA_LIMIT:1500], df_neg[DATA_LIMIT:1500]))\n",
    "\n",
    "def process_text(input_string, return_string=False, stem=False):\n",
    "    text = nlp(u'' + input_string)\n",
    "    if stem == True:\n",
    "        text = [tok.lemma_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    else:\n",
    "        text = [tok.lower_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    if return_string == True:\n",
    "        return \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:18<00:00, 14.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make this statement true to run from scratch [It takes time to process the text]\n",
    "if 1 != 0:\n",
    "    wordlist = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        wordlist.append(process_text(df['review'].iloc[i]))\n",
    "        \n",
    "    with open('vocabulary.txt', 'wb') as vocabulary:\n",
    "        pickle.dump(wordlist, vocabulary)\n",
    "    vocabulary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# hs = Hierarchical softmax, min_count -> excludes token less than that frequency)\n",
    "w2v_model = Word2Vec(window=5, workers=multiprocessing.cpu_count(), iter=100, min_count=1, hs = 1, negative=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=0, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=22449, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 555 ms, total: 1min 4s\n",
      "Wall time: 17.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20548851, 21977100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time w2v_model.train(wordlist, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Dictionary(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['cat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('truck', 0.4335528314113617),\n",
       " ('injured', 0.37404462695121765),\n",
       " ('midway', 0.36831551790237427),\n",
       " ('reminiscent', 0.35472363233566284),\n",
       " ('faultless', 0.3506928086280823),\n",
       " ('flight', 0.34735554456710815),\n",
       " ('bed', 0.34097349643707275),\n",
       " ('blowgun', 0.33984512090682983),\n",
       " ('quickly', 0.33917537331581116),\n",
       " ('steal', 0.3371168076992035)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a numpy empty/random matrix with dimension of [vocsize+1 * embedding dimension]\n",
    "2. Load the embeddings into that word\n",
    "3. Create Keras embedding layer with the same configuration and load weights there\n",
    "4. Train a RNN/CNN to classify [optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding = np.zeros((len(vocabulary) + 1, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vocabulary)):\n",
    "    embedding[i+1] = w2v_model.wv[vocabulary[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, GRU, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for review in wordlist:\n",
    "    X.append(np.array(vocabulary.doc2idx(review)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(X, value=0, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21, 49, 38, 31, 32,\n",
       "        6, 16, 21,  2, 21, 37, 21, 25,  3, 26,  1,  7, 21, 52, 26, 34,  5,\n",
       "       22, 15, 24,  8, 34,  4, 36, 35, 44, 40, 17, 31, 47, 11, 46, 13, 44,\n",
       "       12, 45, 41, 33, 27, 20, 31, 30, 43, 39, 20, 50, 14, 45, 21, 38, 51,\n",
       "       43, 19, 29, 48, 10, 28,  9, 46, 31, 18, 21, 42, 23], dtype=int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.ones(1000), np.zeros(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.6535 - acc: 0.6093 - val_loss: 0.9403 - val_acc: 0.2067\n",
      "Epoch 2/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.5486 - acc: 0.7236 - val_loss: 1.1487 - val_acc: 0.2133\n",
      "Epoch 3/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.4861 - acc: 0.7693 - val_loss: 1.0742 - val_acc: 0.3767\n",
      "Epoch 4/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.4289 - acc: 0.8071 - val_loss: 0.9353 - val_acc: 0.5917\n",
      "Epoch 5/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.3617 - acc: 0.8457 - val_loss: 0.8154 - val_acc: 0.6483\n",
      "Epoch 6/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.3317 - acc: 0.8571 - val_loss: 0.7449 - val_acc: 0.6683\n",
      "Epoch 7/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.3022 - acc: 0.8729 - val_loss: 0.8119 - val_acc: 0.6467\n",
      "Epoch 8/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.2600 - acc: 0.8921 - val_loss: 0.9614 - val_acc: 0.6217\n",
      "Epoch 9/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.2522 - acc: 0.8986 - val_loss: 0.9004 - val_acc: 0.5800\n",
      "Epoch 10/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.2684 - acc: 0.8986 - val_loss: 0.9631 - val_acc: 0.6200\n",
      "Epoch 11/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.2597 - acc: 0.9029 - val_loss: 0.7604 - val_acc: 0.6833\n",
      "Epoch 12/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.2280 - acc: 0.9171 - val_loss: 0.6815 - val_acc: 0.7267\n",
      "Epoch 13/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1917 - acc: 0.9286 - val_loss: 1.1862 - val_acc: 0.5617\n",
      "Epoch 14/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1699 - acc: 0.9379 - val_loss: 0.7919 - val_acc: 0.7267\n",
      "Epoch 15/15\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 0.1657 - acc: 0.9464 - val_loss: 0.5517 - val_acc: 0.8017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f713e5e3e48>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocabulary) + 1, 100, weights=[embedding], trainable=False))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
